{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vikranth3140/Startup-Success-Prediction/blob/main/KNN_%2B_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/startup data.csv')\n",
        "\n",
        "# Display basic information\n",
        "print(\"Data Info:\\n\", data.info())\n",
        "print(\"First few rows:\\n\", data.head())\n",
        "\n",
        "# Select features and target variable\n",
        "target_column = 'has_VC'  # Replace with your actual target column\n",
        "X = data.drop(columns=[target_column])\n",
        "y = data[target_column]\n",
        "\n",
        "# Handle missing values and scaling\n",
        "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Create pipelines for numeric and categorical features\n",
        "numeric_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# If there were categorical features, you could create a categorical pipeline as well\n",
        "# However, in your sample, we only see numeric data.\n",
        "\n",
        "# Combine pipelines using ColumnTransformer if there are both types\n",
        "# from sklearn.compose import ColumnTransformer\n",
        "# preprocessor = ColumnTransformer(\n",
        "#     transformers=[\n",
        "#         ('num', numeric_pipeline, numeric_features),\n",
        "#         ('cat', categorical_pipeline, categorical_features)\n",
        "#     ])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Optional: Display confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Optional: Feature importance\n",
        "feature_importances = rf_classifier.feature_importances_\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance:\\n\", importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-8cRTEhXKIs",
        "outputId": "99bacc4f-98ad-4f2c-cdd9-458168262b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 120 entries, 0 to 119\n",
            "Data columns (total 12 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   latitude                120 non-null    float64\n",
            " 1   longitude               120 non-null    float64\n",
            " 2   age_first_funding_year  120 non-null    float64\n",
            " 3   age_last_funding_year   120 non-null    float64\n",
            " 4   relationships           120 non-null    int64  \n",
            " 5   funding_rounds          120 non-null    int64  \n",
            " 6   funding_total_usd       120 non-null    int64  \n",
            " 7   milestones              120 non-null    int64  \n",
            " 8   has_VC                  120 non-null    int64  \n",
            " 9   has_angel               120 non-null    int64  \n",
            " 10  avg_participants        120 non-null    float64\n",
            " 11  is_top500               120 non-null    int64  \n",
            "dtypes: float64(5), int64(7)\n",
            "memory usage: 11.4 KB\n",
            "Data Info:\n",
            " None\n",
            "First few rows:\n",
            "     latitude   longitude  age_first_funding_year  age_last_funding_year  \\\n",
            "0  37.779281 -122.419236                  0.0000                 1.6685   \n",
            "1  37.406914 -122.090370                  4.5452                 4.5452   \n",
            "2  37.422859 -122.045217                  1.3534                 2.1644   \n",
            "3  40.739010  -73.997259                  2.6575                 2.6575   \n",
            "4  42.546483  -71.173667                  2.7836                10.9507   \n",
            "\n",
            "   relationships  funding_rounds  funding_total_usd  milestones  has_VC  \\\n",
            "0              2               2            1300000           1       1   \n",
            "1              3               1            7500000           1       0   \n",
            "2              3               2           10500000           1       0   \n",
            "3              1               1            4000000           1       0   \n",
            "4             10               3           19009671           1       0   \n",
            "\n",
            "   has_angel  avg_participants  is_top500  \n",
            "0          1               1.0          1  \n",
            "1          0               3.0          1  \n",
            "2          0               2.0          1  \n",
            "3          0               1.0          1  \n",
            "4          0               2.0          1  \n",
            "Accuracy: 0.7083333333333334\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.75      0.77        16\n",
            "           1       0.56      0.62      0.59         8\n",
            "\n",
            "    accuracy                           0.71        24\n",
            "   macro avg       0.68      0.69      0.68        24\n",
            "weighted avg       0.72      0.71      0.71        24\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[12  4]\n",
            " [ 3  5]]\n",
            "\n",
            "Feature Importance:\n",
            "                    Feature  Importance\n",
            "3    age_last_funding_year    0.237996\n",
            "2   age_first_funding_year    0.132528\n",
            "5           funding_rounds    0.111764\n",
            "6        funding_total_usd    0.110023\n",
            "0                 latitude    0.093985\n",
            "4            relationships    0.091113\n",
            "1                longitude    0.089042\n",
            "9         avg_participants    0.055117\n",
            "7               milestones    0.034029\n",
            "8                has_angel    0.029314\n",
            "10               is_top500    0.015090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create a pipeline for KNN\n",
        "pipeline_knn = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', KNeighborsClassifier(n_neighbors=5))  # You can adjust n_neighbors\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "pipeline_knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_knn = pipeline_knn.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
        "print(\"\\nKNN Classification Report:\\n\", classification_report(y_test, y_pred_knn))\n",
        "print(\"\\nKNN Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_knn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEKWy_gFXeuH",
        "outputId": "f8e6a0cb-150a-4944-b059-fd0aa604735a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.7916666666666666\n",
            "\n",
            "KNN Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.94      0.86        16\n",
            "           1       0.80      0.50      0.62         8\n",
            "\n",
            "    accuracy                           0.79        24\n",
            "   macro avg       0.79      0.72      0.74        24\n",
            "weighted avg       0.79      0.79      0.78        24\n",
            "\n",
            "\n",
            "KNN Confusion Matrix:\n",
            " [[15  1]\n",
            " [ 4  4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/startup data.csv')\n",
        "\n",
        "# Select features and target variable\n",
        "target_column = 'has_VC'  # Replace with your actual target column\n",
        "X = data.drop(columns=[target_column])\n",
        "y = data[target_column]\n",
        "\n",
        "# Handle missing values and scaling\n",
        "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Create a pipeline for SVM\n",
        "pipeline_svm = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', SVC(kernel='linear', random_state=42))  # You can change the kernel\n",
        "])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "pipeline_svm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_svm = pipeline_svm.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"\\nSVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
        "print(\"\\nSVM Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjMz57urXhr0",
        "outputId": "4fad0b0e-eb10-4150-f59c-3235b4dc5f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.75\n",
            "\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81        16\n",
            "           1       0.62      0.62      0.62         8\n",
            "\n",
            "    accuracy                           0.75        24\n",
            "   macro avg       0.72      0.72      0.72        24\n",
            "weighted avg       0.75      0.75      0.75        24\n",
            "\n",
            "\n",
            "SVM Confusion Matrix:\n",
            " [[13  3]\n",
            " [ 3  5]]\n"
          ]
        }
      ]
    }
  ]
}